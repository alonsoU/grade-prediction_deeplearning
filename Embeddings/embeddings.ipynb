{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Embedding Notebook for clarity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the libraries and funtions we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import classfolder.frameprocess as pre\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "\n",
    "def get_run_dir(model_path):\n",
    "\n",
    "    rootpath = pl.Path(os.curdir)\n",
    "    model_path = pl.Path(model_path) / time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    for part in model_path.parts:\n",
    "        rootpath /= part\n",
    "        rootpath.mkdir(exist_ok=True)\n",
    "    return rootpath\n",
    "def split_label(DataFrame, label='nota', label_toframe=True):\n",
    "    # Separa dataframe de su designado target o label\n",
    "    if label_toframe:\n",
    "        data_label = DataFrame.loc[:,label].to_frame()\n",
    "    else:\n",
    "        data_label = DataFrame.loc[:,label]\n",
    "    data = DataFrame.drop([label], axis=1)\n",
    "    return data, data_label\n",
    "def batching_dataset(train, target, batch_size=32, prefetch=1):\n",
    "    # Recive train data y target, lo trasforma en tf.data.Dataset,\n",
    "    # lo junta en tuplas(requerido por Model.fit(x) al pasar objeto Dataset),\n",
    "    # agrupa la secuencia en bachas y finalmente aplica prefetch eficiencia de\n",
    "    # lectura.\n",
    "    # batch_size: tamaño de la bacha.\n",
    "    # prefetch: cantidad de datos al que se le aplica prefetch.\n",
    "    train = tf.data.Dataset.from_tensor_slices(train)\n",
    "    target = tf.data.Dataset.from_tensor_slices(target)\n",
    "    data = tf.data.Dataset.zip((train, target))\n",
    "    data = data.batch(batch_size).prefetch(prefetch)\n",
    "    return data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "def norm(array):\n",
    "    \"\"\"\n",
    "    Aqui las notas pasaran a escala logaritmica. (experimental)\n",
    "    \"\"\"\n",
    "    a = array\n",
    "    # a /= 70\n",
    "    # a = np.exp(a/70)\n",
    "    standard = StandardScaler()\n",
    "    # power = PowerTzransformer(method='yeo-johnson')\n",
    "    a = np.array(a).reshape(-1, 1)\n",
    "    # a = power.fit_transform(a)\n",
    "    a = standard.fit_transform(a)\n",
    "    a = a.reshape(-1)\n",
    "    # a = np.log(a)\n",
    "    return a\n",
    "def sscaler_frame(data):\n",
    "    mask = data['sede'] == 'colegio mayor tobalaba'\n",
    "    data.loc[mask, 'nota'] = data.loc[mask, 'nota'].to_frame().apply(norm,\n",
    "        axis=0, raw=True)\n",
    "    data.loc[~mask, 'nota'] = data.loc[~mask, 'nota'].to_frame().apply(norm,\n",
    "        axis=0, raw=True)\n",
    "    return data\n",
    "    \n",
    "def name_toindex(names, guide=multi_label):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(names, list):\n",
    "        in_list = []\n",
    "        for name in names:\n",
    "            i = guide.index(name)\n",
    "            in_list.append(i)\n",
    "        return in_list\n",
    "    elif isinstance(names, str):\n",
    "        i = guide.index(name)\n",
    "        return i\n",
    "    else:\n",
    "        raise TypeError(f'name must be {repr(list)} or {repr(str)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sede</th>\n",
       "      <th>ano</th>\n",
       "      <th>curso</th>\n",
       "      <th>asignatura</th>\n",
       "      <th>profesor-rut</th>\n",
       "      <th>semestre</th>\n",
       "      <th>alumno-rut</th>\n",
       "      <th>nota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colegio mayor de penalolen</td>\n",
       "      <td>2004</td>\n",
       "      <td>basica 1-a</td>\n",
       "      <td>tecnologia</td>\n",
       "      <td>8745858-k</td>\n",
       "      <td>segundo</td>\n",
       "      <td>19889609-8</td>\n",
       "      <td>67.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>colegio mayor de penalolen</td>\n",
       "      <td>2004</td>\n",
       "      <td>basica 1-a</td>\n",
       "      <td>idioma extranjero (ingles)</td>\n",
       "      <td>11854296-7</td>\n",
       "      <td>primer</td>\n",
       "      <td>19889609-8</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>colegio mayor de penalolen</td>\n",
       "      <td>2004</td>\n",
       "      <td>basica 1-a</td>\n",
       "      <td>tecnologia</td>\n",
       "      <td>8745858-k</td>\n",
       "      <td>primer</td>\n",
       "      <td>19889609-8</td>\n",
       "      <td>67.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colegio mayor de penalolen</td>\n",
       "      <td>2004</td>\n",
       "      <td>basica 1-a</td>\n",
       "      <td>educacion fisica y salud</td>\n",
       "      <td>9786497-7</td>\n",
       "      <td>segundo</td>\n",
       "      <td>19889609-8</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colegio mayor de penalolen</td>\n",
       "      <td>2004</td>\n",
       "      <td>basica 1-a</td>\n",
       "      <td>artes visuales</td>\n",
       "      <td>8745858-k</td>\n",
       "      <td>primer</td>\n",
       "      <td>19889609-8</td>\n",
       "      <td>68.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486429</th>\n",
       "      <td>colegio mayor tobalaba</td>\n",
       "      <td>2017</td>\n",
       "      <td>media 4-b</td>\n",
       "      <td>condicion fisica y motriz asociada a salud y c...</td>\n",
       "      <td>17506017-0</td>\n",
       "      <td>primer</td>\n",
       "      <td>20282314-9</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486430</th>\n",
       "      <td>colegio mayor tobalaba</td>\n",
       "      <td>2017</td>\n",
       "      <td>media 4-b</td>\n",
       "      <td>condicion fisica y motriz asociada a salud y c...</td>\n",
       "      <td>17506017-0</td>\n",
       "      <td>segundo</td>\n",
       "      <td>20282314-9</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486431</th>\n",
       "      <td>colegio mayor tobalaba</td>\n",
       "      <td>2017</td>\n",
       "      <td>media 4-b</td>\n",
       "      <td>biologia</td>\n",
       "      <td>13935732-9</td>\n",
       "      <td>segundo</td>\n",
       "      <td>20282314-9</td>\n",
       "      <td>50.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486432</th>\n",
       "      <td>colegio mayor tobalaba</td>\n",
       "      <td>2017</td>\n",
       "      <td>media 4-b</td>\n",
       "      <td>idioma extranjero (ingles)</td>\n",
       "      <td>12475545-k</td>\n",
       "      <td>primer</td>\n",
       "      <td>20282314-9</td>\n",
       "      <td>68.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486433</th>\n",
       "      <td>colegio mayor tobalaba</td>\n",
       "      <td>2017</td>\n",
       "      <td>media 4-b</td>\n",
       "      <td>idioma extranjero (ingles)</td>\n",
       "      <td>12475545-k</td>\n",
       "      <td>segundo</td>\n",
       "      <td>20282314-9</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486434 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sede   ano       curso  \\\n",
       "0       colegio mayor de penalolen  2004  basica 1-a   \n",
       "1       colegio mayor de penalolen  2004  basica 1-a   \n",
       "2       colegio mayor de penalolen  2004  basica 1-a   \n",
       "3       colegio mayor de penalolen  2004  basica 1-a   \n",
       "4       colegio mayor de penalolen  2004  basica 1-a   \n",
       "...                            ...   ...         ...   \n",
       "486429      colegio mayor tobalaba  2017   media 4-b   \n",
       "486430      colegio mayor tobalaba  2017   media 4-b   \n",
       "486431      colegio mayor tobalaba  2017   media 4-b   \n",
       "486432      colegio mayor tobalaba  2017   media 4-b   \n",
       "486433      colegio mayor tobalaba  2017   media 4-b   \n",
       "\n",
       "                                               asignatura profesor-rut  \\\n",
       "0                                              tecnologia    8745858-k   \n",
       "1                              idioma extranjero (ingles)   11854296-7   \n",
       "2                                              tecnologia    8745858-k   \n",
       "3                                educacion fisica y salud    9786497-7   \n",
       "4                                          artes visuales    8745858-k   \n",
       "...                                                   ...          ...   \n",
       "486429  condicion fisica y motriz asociada a salud y c...   17506017-0   \n",
       "486430  condicion fisica y motriz asociada a salud y c...   17506017-0   \n",
       "486431                                           biologia   13935732-9   \n",
       "486432                         idioma extranjero (ingles)   12475545-k   \n",
       "486433                         idioma extranjero (ingles)   12475545-k   \n",
       "\n",
       "       semestre  alumno-rut  nota  \n",
       "0       segundo  19889609-8  67.6  \n",
       "1        primer  19889609-8  70.0  \n",
       "2        primer  19889609-8  67.6  \n",
       "3       segundo  19889609-8  69.0  \n",
       "4        primer  19889609-8  68.8  \n",
       "...         ...         ...   ...  \n",
       "486429   primer  20282314-9  70.0  \n",
       "486430  segundo  20282314-9  70.0  \n",
       "486431  segundo  20282314-9  50.2  \n",
       "486432   primer  20282314-9  68.6  \n",
       "486433  segundo  20282314-9  70.0  \n",
       "\n",
       "[486434 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = pl.Path('D:/Proyectos/Python_proyects/MachineLearning/grade-prediction_deeplearning/Embeddings/data/archivos_mayor-cleanframe.csv')\n",
    "df = pd.read_csv(path, delimiter=',', low_memory=False, index_col=0,)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# names: ['sede', 'ano', 'curso', 'asignatura', 'profesor-rut',\n",
    "# 'semestre', 'alumno-rut', 'nota']\n",
    "subjects = df['asignatura'].unique()\n",
    "subj = df['asignatura'].value_counts().index.to_numpy()\n",
    "# print(subjects)\n",
    "# print(subj)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "def split_data(DataFrame, split=split, prop_column='asignatura'):\n",
    "    # Separa indices de dataframe en train y test data, mediante objeto\n",
    "    # scikit-learn, para luego construir un generador pero retorna diferentes\n",
    "    # particiones del dataframe en cada interación.\n",
    "    # split: instancia de sk-learn dedicada a generar indices en dataframe\n",
    "    # prop_column: columna que se utiliza como mascara para la partición,\n",
    "    #    correspondiendo la proporción de los elementos en esta.\n",
    "    #\n",
    "    for train_index, test_index in split.split(DataFrame, DataFrame[prop_column]):\n",
    "        train_frame = DataFrame.iloc[train_index].copy()\n",
    "        test_frame = DataFrame.iloc[test_index].copy()\n",
    "        yield train_frame, test_frame\n",
    "\n",
    "train_data, test_data = split_data(df).__next__()\n",
    "train_data, validation_data = split_data(train_data).__next__()\n",
    "test_data.to_csv('D:/Proyectos/Python_proyects/MachineLearning/grade-prediction_deeplearning/Embeddings/data/test_embeddings_re0.csv', index=False)\n",
    "train_data['nota'].hist(grid=True, bins=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota estandarizada máxima:  1.2486503906151145\n",
      "Nota estandarizada mínima:  -6.131031467300419\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = sscaler_frame(train_data)\n",
    "validation_data = sscaler_frame(validation_data)\n",
    "test_data = sscaler_frame(test_data)\n",
    "\n",
    "print(\"Nota estandarizada máxima: \", train_data['nota'].max())\n",
    "print(\"Nota estandarizada mínima: \", train_data['nota'].min())\n",
    "train_data['nota'].hist(grid=True, bins=140)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sede', 'ano', 'curso', 'semestre', 'asignatura', 'profesor-rut']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alumno-rut</th>\n",
       "      <th>nota</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sede</th>\n",
       "      <th>ano</th>\n",
       "      <th>curso</th>\n",
       "      <th>semestre</th>\n",
       "      <th>asignatura</th>\n",
       "      <th>profesor-rut</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">colegio mayor de penalolen</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2004</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">basica 1-a</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">primer</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">artes visuales</th>\n",
       "      <th>8745858-k</th>\n",
       "      <td>19838614-6</td>\n",
       "      <td>0.993512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745858-k</th>\n",
       "      <td>19687562-k</td>\n",
       "      <td>1.141426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745858-k</th>\n",
       "      <td>19688073-9</td>\n",
       "      <td>0.993512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745858-k</th>\n",
       "      <td>19606105-3</td>\n",
       "      <td>0.993512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745858-k</th>\n",
       "      <td>14729974-5</td>\n",
       "      <td>0.993512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">colegio mayor tobalaba</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2017</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">media 4-b</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">segundo</th>\n",
       "      <th>quimica diferenciada</th>\n",
       "      <th>15716225-k</th>\n",
       "      <td>20108716-3</td>\n",
       "      <td>-0.497717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">termodinamica</th>\n",
       "      <th>13077848-8</th>\n",
       "      <td>20298165-8</td>\n",
       "      <td>-0.148443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13077848-8</th>\n",
       "      <td>20295895-8</td>\n",
       "      <td>-0.264868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13077848-8</th>\n",
       "      <td>20283660-7</td>\n",
       "      <td>-0.148443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13077848-8</th>\n",
       "      <td>20427803-2</td>\n",
       "      <td>0.666528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311317 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       alumno-rut  \\\n",
       "sede                       ano  curso      semestre asignatura           profesor-rut               \n",
       "colegio mayor de penalolen 2004 basica 1-a primer   artes visuales       8745858-k     19838614-6   \n",
       "                                                                         8745858-k     19687562-k   \n",
       "                                                                         8745858-k     19688073-9   \n",
       "                                                                         8745858-k     19606105-3   \n",
       "                                                                         8745858-k     14729974-5   \n",
       "...                                                                                           ...   \n",
       "colegio mayor tobalaba     2017 media 4-b  segundo  quimica diferenciada 15716225-k    20108716-3   \n",
       "                                                    termodinamica        13077848-8    20298165-8   \n",
       "                                                                         13077848-8    20295895-8   \n",
       "                                                                         13077848-8    20283660-7   \n",
       "                                                                         13077848-8    20427803-2   \n",
       "\n",
       "                                                                                           nota  \n",
       "sede                       ano  curso      semestre asignatura           profesor-rut            \n",
       "colegio mayor de penalolen 2004 basica 1-a primer   artes visuales       8745858-k     0.993512  \n",
       "                                                                         8745858-k     1.141426  \n",
       "                                                                         8745858-k     0.993512  \n",
       "                                                                         8745858-k     0.993512  \n",
       "                                                                         8745858-k     0.993512  \n",
       "...                                                                                         ...  \n",
       "colegio mayor tobalaba     2017 media 4-b  segundo  quimica diferenciada 15716225-k   -0.497717  \n",
       "                                                    termodinamica        13077848-8   -0.148443  \n",
       "                                                                         13077848-8   -0.264868  \n",
       "                                                                         13077848-8   -0.148443  \n",
       "                                                                         13077848-8    0.666528  \n",
       "\n",
       "[311317 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Iterator que entrega grupos, en este caso de curso por asignatura\n",
    "multi_label = ['sede', 'ano', 'curso', 'semestre', 'asignatura',\n",
    "    'profesor-rut']\n",
    "def indexed_frame(data):\n",
    "    \"\"\"\n",
    "    ### Indexing the student data frame:\n",
    "    Sorted in a special arrange so every dataset from a groupby will be a specific course in time\n",
    "    \"\"\"\n",
    "    data_indexed = data.set_index(multi_label, drop=True).sort_index()\n",
    "    return data_indexed\n",
    "\n",
    "train_data_indx = indexed_frame(train_data)\n",
    "names = train_data_indx.index.names\n",
    "print(names)\n",
    "validation_data_indx = indexed_frame(validation_data)\n",
    "test_data_indx = indexed_frame(test_data)#^2+145 # WHY?\n",
    "train_data_indx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow tables from Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to have a tensorflow optimized dataframe that can be processed by CUDA thanks to a tensorflow decorator (tf.function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numero total de datasets:  20068\n",
      "\n",
      "Curso con la menor cantidad:  1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tablas de variables categoricas basado en clase de indexado tensorflow\n",
    "tf_tables = pre.LookupFrame(df,\n",
    "    ['asignatura', 'curso', 'ano', 'semestre', 'alumno-rut', 'profesor-rut',],\n",
    "    prop_bucket=0.01,\n",
    "    )\n",
    "\n",
    "# Numero naximo de alumnos en un curso o clase de profesor en particular\n",
    "maxnum = 0\n",
    "minnum = 20\n",
    "numdata = 0\n",
    "for index, data in train_data_indx.groupby(level=names).__iter__():\n",
    "    curr_len = data.shape[0]\n",
    "    maxnum = np.amax([curr_len, maxnum])\n",
    "    minnum = np.amin([curr_len, minnum])\n",
    "    numdata+=1\n",
    "maxnum += 5\n",
    "print(\"\\nNumero total de datasets: \", numdata)\n",
    "print(\"\\nCurso con la menor cantidad: \", minnum)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_groups = train_data_indx.groupby(level=names)\n",
    "\n",
    "def train_data_gen(groups=train_groups):\n",
    "    \"\"\"\n",
    "    From an indexed Dataframe,  \n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for index, frame in iter(groups):\n",
    "            matrix = frame.to_numpy()\n",
    "            students = matrix[:,0]\n",
    "            grades = matrix[:,1].astype(np.float64)\n",
    "            index = np.array([str(i) for i in index])\n",
    "            yield (index, students), grades\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(train_data_gen,\n",
    "    output_types=((tf.string, tf.string), tf.float64),\n",
    "    output_shapes=((tf.TensorShape([len(multi_label)]),\n",
    "        tf.TensorShape([None])),\n",
    "        tf.TensorShape([None])),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = name_toindex(['curso', 'semestre', 'profesor-rut'])\n",
    "@tf.function\n",
    "def transform_data(X, y):\n",
    "    \"\"\"\n",
    "    ### Tensorflow enhanced function:\n",
    "    Transform the grouby dataset (by courses) in a way that is fit for the tensorflow model.\n",
    "    \"\"\"\n",
    "    global match\n",
    "    index, _students = X\n",
    "    grades = y\n",
    "    students = tf_tables['alumno-rut'].lookup(_students)\n",
    "\n",
    "    # Busca el index que le corresponde al nombre en la lista de\n",
    "    # Multilabel\n",
    "    level = tf_tables['curso'].lookup(index[match[0]])\n",
    "    level = tf.reshape(level, [1])\n",
    "    semester = tf_tables['semestre'].lookup(index[match[1]])\n",
    "    semester = tf.reshape(semester, [1])\n",
    "    profesor =  tf_tables['profesor-rut'].lookup(index[match[2]])\n",
    "    profesor = tf.reshape(profesor, [1])\n",
    "\n",
    "    _subjects = tf.constant(subjects, dtype=tf.string)\n",
    "    all_subjects = tf_tables['asignatura'].lookup(_subjects)\n",
    "    all_subjects = tf.reshape(all_subjects, [len(subjects)])\n",
    "\n",
    "    return {'input_students': students,\n",
    "        'input_level': level,\n",
    "        'input_semester': semester,\n",
    "        'input_profesor': profesor,\n",
    "        'input_subjects': all_subjects,\n",
    "        }, {'output_grades': grades}\n",
    "buffer = numdata + 1\n",
    "train_dataset = train_dataset.shuffle(buffer)\n",
    "train_dataset = train_dataset.map(lambda x, y: transform_data(x, y),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    # deterministic=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "steps_per_epoch = numdata//batch_size\n",
    "def batching(dataset):\n",
    "    dataset = dataset.padded_batch(batch_size,\n",
    "        padded_shapes=({'input_students': maxnum,\n",
    "            'input_level': 1,\n",
    "            'input_semester': 1,\n",
    "            'input_profesor': 1,\n",
    "            'input_subjects': len(subjects),\n",
    "            }, {'output_grades': maxnum}),\n",
    "        # padded_values=0,\n",
    "        ).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = batching(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension del embedding para todos los inputs\n",
    "embed_dim = 2 ** 5 #8 #7 cambio realizado el 20-09-09\n",
    "# Embedding del un curso con un profesor en particular\n",
    "total_student = tf_tables.get_lenght('alumno-rut')\n",
    "input_students = keras.layers.Input(shape=[maxnum],\n",
    "    batch_size=batch_size,\n",
    "    name=\"input_students\",\n",
    "    # ragged=True,\n",
    "    )\n",
    "students = keras.layers.Embedding(input_dim=total_student,\n",
    "    output_dim=embed_dim,\n",
    "    mask_zero=True,\n",
    "    embeddings_initializer=keras.initializers.GlorotNormal(),\n",
    "    name=\"alumno-rut\",\n",
    "    )\n",
    "students_tensor = students(input_students)\n",
    "noise = keras.layers.GaussianNoise(stddev=0.8)\n",
    "students_tensor = noise(students_tensor)\n",
    "\n",
    "# Embedding del nivel conjunto con el semestre, será una multiplicación de estos dos.\n",
    "# Como los diccionarios de tensorflow parten de 0, se suma 1 al tensor\n",
    "# para asegurar que dos tuplas; (nivel, semestre), no repita sus indices\n",
    "total_levels = tf_tables.get_lenght('ano')\n",
    "num_semesters = tf_tables.get_lenght('semestre')\n",
    "input_level = keras.layers.Input(shape=[1],\n",
    "    name=\"input_level\")\n",
    "input_semester = keras.layers.Input(shape=[1],\n",
    "    name=\"input_semester\")\n",
    "combined = input_semester*input_level\n",
    "\n",
    "semester = keras.layers.Embedding(input_dim=total_levels*num_semesters,\n",
    "    output_dim=embed_dim,\n",
    "    mask_zero=True,\n",
    "    embeddings_initializer=keras.initializers.GlorotNormal(),\n",
    "    name=\"embed_level-semester\",\n",
    "    )\n",
    "semester_vec = semester(combined)\n",
    "\n",
    "# Suma del embedding correspondientes a los alumnos y \"semestre\", respecticamente\n",
    "# Notar que semester_vec es la suma del embed original semestre junto con embed\n",
    "# nivel.\n",
    "course_tensor =  students_tensor + semester_vec\n",
    "\n",
    "# Embedding de todas las asignaturas existentes\n",
    "total_subjects = tf_tables.get_lenght('asignatura')\n",
    "input_subjects = keras.Input(shape=[len(subjects)],\n",
    "    name=\"input_subjects\")\n",
    "embed_subjects = keras.layers.Embedding(input_dim=total_subjects,\n",
    "    output_dim=embed_dim,\n",
    "    mask_zero=True,\n",
    "    embeddings_initializer=keras.initializers.GlorotNormal(),\n",
    "    name=\"asignatura\",\n",
    "    )\n",
    "subjects_tensor = embed_subjects(input_subjects)\n",
    "\n",
    "# Vector de el profesor del curso\n",
    "total_profesors = tf_tables.get_lenght('profesor-rut')\n",
    "input_profesor = keras.Input(shape=[1],\n",
    "    name=\"input_profesor\"\n",
    "    )\n",
    "profesors = keras.layers.Embedding(input_dim=total_profesors,\n",
    "    output_dim=embed_dim,\n",
    "    mask_zero=True,\n",
    "    embeddings_initializer=keras.initializers.GlorotNormal(),\n",
    "    name=\"profesor-rut\",\n",
    "    )\n",
    "profesor_vec = profesors(input_profesor)\n",
    "noise2 = keras.layers.GaussianNoise(stddev=0.4)\n",
    "profesor_vec = noise2(profesor_vec)\n",
    "\n",
    "# Self-Atencion de cada curso, es decir de cada \"alumno-vector\" con todos los\n",
    "# demas\n",
    "# \"\"\"fuera self-attention\"\"\"\n",
    "a1 = keras.layers.Attention(use_scale=True)([course_tensor, course_tensor])\n",
    "# a1 = course_tensor\n",
    "\n",
    "# Nuevamente Atencion por parte de cada \"atencion del alumno-vector\" hacia\n",
    "# todas las asignaturas existentes\n",
    "a2 = keras.layers.Attention(use_scale=True)([a1, subjects_tensor])\n",
    "\n",
    "# Luego de consegir el vector de atención que le dedican los alumnos del curso,\n",
    "# este se proyecta con el vector del para medir su influecia, dando la nota\n",
    "# especifica del alumno en la asignatura correspondiente\n",
    "output_grades = keras.layers.Dot(axes=2, name=\"output_grades\")([a2, profesor_vec])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model engine and Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_students (InputLayer)    [(64, 50)]           0           []                               \n",
      "                                                                                                  \n",
      " input_semester (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_level (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " alumno-rut (Embedding)         (64, 50, 32)         191904      ['input_students[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 1)            0           ['input_semester[0][0]',         \n",
      "                                                                  'input_level[0][0]']            \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNoise)  (64, 50, 32)        0           ['alumno-rut[0][0]']             \n",
      "                                                                                                  \n",
      " embed_level-semester (Embeddin  (None, 1, 32)       4256        ['tf.math.multiply[0][0]']       \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (64, 50, 32)        0           ['gaussian_noise[0][0]',         \n",
      " da)                                                              'embed_level-semester[0][0]']   \n",
      "                                                                                                  \n",
      " input_subjects (InputLayer)    [(None, 42)]         0           []                               \n",
      "                                                                                                  \n",
      " input_profesor (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " attention (Attention)          (64, 50, 32)         1           ['tf.__operators__.add[0][0]',   \n",
      "                                                                  'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " asignatura (Embedding)         (None, 42, 32)       1504        ['input_subjects[0][0]']         \n",
      "                                                                                                  \n",
      " profesor-rut (Embedding)       (None, 1, 32)        12032       ['input_profesor[0][0]']         \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        (64, 50, 32)         1           ['attention[0][0]',              \n",
      "                                                                  'asignatura[0][0]']             \n",
      "                                                                                                  \n",
      " gaussian_noise_1 (GaussianNois  (None, 1, 32)       0           ['profesor-rut[0][0]']           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " output_grades (Dot)            (64, 50, 1)          0           ['attention_1[0][0]',            \n",
      "                                                                  'gaussian_noise_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 209,698\n",
      "Trainable params: 209,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Proyectos\\Python_proyects\\Algos-y-Estructuras\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "encoder = keras.Model(inputs=[input_students,\n",
    "        input_level,\n",
    "        input_semester,\n",
    "        input_subjects,\n",
    "        input_profesor\n",
    "        ],\n",
    "    outputs=[output_grades])\n",
    "encoder.summary()\n",
    "\n",
    "run_logdir = get_run_dir(\"pCM_logs/clean_subjects/glorot/5bit-dim/noise_s08-p04/subj_focus.h5\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=run_logdir,\n",
    "    write_images=True,\n",
    "    histogram_freq=5,\n",
    "    # embeddings_freq=5,\n",
    "    )\n",
    "early_cb = keras.callbacks.EarlyStopping(patience=35,\n",
    "    restore_best_weights=True)\n",
    "def best_lr(history):\n",
    "    lrs = np.array(history.history[\"lr\"])\n",
    "    losses = np.array(history.history[\"loss\"])\n",
    "    dloss = losses[1:] - losses[:-1]\n",
    "    min_index = np.argmin(dloss)\n",
    "    return lrs[min_index]\n",
    "init_lr = 1e-10\n",
    "final_lr = 1e-2\n",
    "total_epochs = 100\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: init_lr*(final_lr/init_lr)**(epoch/total_epochs)\n",
    ")\n",
    "\n",
    "encoder.compile(loss=tf.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(lr=0.00012),\n",
    "    metrics=['mean_absolute_error'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and Validation data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 18s 84ms/step - loss: 0.1040 - mean_absolute_error: 0.0892\n",
      "Epoch 1/100\n",
      "313/313 [==============================] - 53s 90ms/step - loss: 0.3207 - mean_absolute_error: 0.3014 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.0000e-10\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.3157 - mean_absolute_error: 0.2983 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.2023e-10\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 0.3170 - mean_absolute_error: 0.2993 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.4454e-10\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 0.3152 - mean_absolute_error: 0.2992 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.7378e-10\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 27s 88ms/step - loss: 0.3183 - mean_absolute_error: 0.2992 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 2.0893e-10\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.3150 - mean_absolute_error: 0.2980 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 2.5119e-10\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.3165 - mean_absolute_error: 0.2993 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 3.0200e-10\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.3189 - mean_absolute_error: 0.3002 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 3.6308e-10\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.3170 - mean_absolute_error: 0.2994 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 4.3652e-10\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.3195 - mean_absolute_error: 0.3002 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 5.2481e-10\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 0.3139 - mean_absolute_error: 0.2982 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 6.3096e-10\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.3179 - mean_absolute_error: 0.2993 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 7.5858e-10\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3161 - mean_absolute_error: 0.2990 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 9.1201e-10\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 16s 52ms/step - loss: 0.3180 - mean_absolute_error: 0.2996 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.0965e-09\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 17s 54ms/step - loss: 0.3176 - mean_absolute_error: 0.2999 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.3183e-09\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.3154 - mean_absolute_error: 0.2985 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.5849e-09\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 0.3155 - mean_absolute_error: 0.2987 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.9055e-09\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.3182 - mean_absolute_error: 0.2999 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 2.2909e-09\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.3176 - mean_absolute_error: 0.2995 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 2.7542e-09\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 0.3173 - mean_absolute_error: 0.3002 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 3.3113e-09\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 0.3168 - mean_absolute_error: 0.2993 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 3.9811e-09\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.3147 - mean_absolute_error: 0.2977 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 4.7863e-09\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 0.3189 - mean_absolute_error: 0.2997 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 5.7544e-09\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 21s 65ms/step - loss: 0.3144 - mean_absolute_error: 0.2982 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 6.9183e-09\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 0.3175 - mean_absolute_error: 0.2992 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 8.3176e-09\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.3147 - mean_absolute_error: 0.2985 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.0000e-08\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.3174 - mean_absolute_error: 0.2997 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.2023e-08\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 21s 69ms/step - loss: 0.3179 - mean_absolute_error: 0.3000 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.4454e-08\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.3166 - mean_absolute_error: 0.2993 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.7378e-08\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.3175 - mean_absolute_error: 0.2993 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 2.0893e-08\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.3184 - mean_absolute_error: 0.3001 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 2.5119e-08\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.3146 - mean_absolute_error: 0.2980 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 3.0200e-08\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.3169 - mean_absolute_error: 0.2994 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 3.6308e-08\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 23s 72ms/step - loss: 0.3169 - mean_absolute_error: 0.2988 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 4.3652e-08\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 0.3161 - mean_absolute_error: 0.2990 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 5.2481e-08\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.3169 - mean_absolute_error: 0.2994 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 6.3096e-08\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.3168 - mean_absolute_error: 0.2990 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 7.5858e-08\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.3160 - mean_absolute_error: 0.2988 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 9.1201e-08\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3205 - mean_absolute_error: 0.3010 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.0965e-07\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.3160 - mean_absolute_error: 0.2985 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.3183e-07\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.3140 - mean_absolute_error: 0.2976 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.5849e-07\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3192 - mean_absolute_error: 0.3001 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 1.9055e-07\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.3169 - mean_absolute_error: 0.2994 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 2.2909e-07\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.3163 - mean_absolute_error: 0.2991 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 2.7542e-07\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.3161 - mean_absolute_error: 0.2992 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 3.3113e-07\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.3187 - mean_absolute_error: 0.2996 - val_loss: 0.0844 - val_mean_absolute_error: 0.0723 - lr: 3.9811e-07\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3159 - mean_absolute_error: 0.2984 - val_loss: 0.0844 - val_mean_absolute_error: 0.0722 - lr: 4.7863e-07\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.3169 - mean_absolute_error: 0.2995 - val_loss: 0.0844 - val_mean_absolute_error: 0.0722 - lr: 5.7544e-07\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.3128 - mean_absolute_error: 0.2974 - val_loss: 0.0844 - val_mean_absolute_error: 0.0722 - lr: 6.9183e-07\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.3186 - mean_absolute_error: 0.3000 - val_loss: 0.0843 - val_mean_absolute_error: 0.0722 - lr: 8.3176e-07\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.3165 - mean_absolute_error: 0.2984 - val_loss: 0.0843 - val_mean_absolute_error: 0.0722 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3179 - mean_absolute_error: 0.2990 - val_loss: 0.0843 - val_mean_absolute_error: 0.0721 - lr: 1.2023e-06\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3168 - mean_absolute_error: 0.2990 - val_loss: 0.0843 - val_mean_absolute_error: 0.0721 - lr: 1.4454e-06\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.3126 - mean_absolute_error: 0.2966 - val_loss: 0.0843 - val_mean_absolute_error: 0.0721 - lr: 1.7378e-06\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.3161 - mean_absolute_error: 0.2987 - val_loss: 0.0843 - val_mean_absolute_error: 0.0720 - lr: 2.0893e-06\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.3179 - mean_absolute_error: 0.2981 - val_loss: 0.0843 - val_mean_absolute_error: 0.0720 - lr: 2.5119e-06\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.3176 - mean_absolute_error: 0.2984 - val_loss: 0.0843 - val_mean_absolute_error: 0.0719 - lr: 3.0200e-06\n",
      "Epoch 58/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3175 - mean_absolute_error: 0.2985 - val_loss: 0.0843 - val_mean_absolute_error: 0.0719 - lr: 3.6308e-06\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.3132 - mean_absolute_error: 0.2954 - val_loss: 0.0842 - val_mean_absolute_error: 0.0719 - lr: 4.3652e-06\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3138 - mean_absolute_error: 0.2963 - val_loss: 0.0842 - val_mean_absolute_error: 0.0718 - lr: 5.2481e-06\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.3169 - mean_absolute_error: 0.2968 - val_loss: 0.0842 - val_mean_absolute_error: 0.0718 - lr: 6.3096e-06\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.3153 - mean_absolute_error: 0.2954 - val_loss: 0.0842 - val_mean_absolute_error: 0.0718 - lr: 7.5858e-06\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.3166 - mean_absolute_error: 0.2959 - val_loss: 0.0841 - val_mean_absolute_error: 0.0718 - lr: 9.1201e-06\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.3158 - mean_absolute_error: 0.2951 - val_loss: 0.0841 - val_mean_absolute_error: 0.0718 - lr: 1.0965e-05\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3141 - mean_absolute_error: 0.2941 - val_loss: 0.0841 - val_mean_absolute_error: 0.0719 - lr: 1.3183e-05\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.3126 - mean_absolute_error: 0.2920 - val_loss: 0.0840 - val_mean_absolute_error: 0.0720 - lr: 1.5849e-05\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.3151 - mean_absolute_error: 0.2928 - val_loss: 0.0840 - val_mean_absolute_error: 0.0723 - lr: 1.9055e-05\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.3131 - mean_absolute_error: 0.2916 - val_loss: 0.0839 - val_mean_absolute_error: 0.0726 - lr: 2.2909e-05\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3116 - mean_absolute_error: 0.2903 - val_loss: 0.0838 - val_mean_absolute_error: 0.0732 - lr: 2.7542e-05\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.3114 - mean_absolute_error: 0.2887 - val_loss: 0.0837 - val_mean_absolute_error: 0.0740 - lr: 3.3113e-05\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.3111 - mean_absolute_error: 0.2878 - val_loss: 0.0836 - val_mean_absolute_error: 0.0753 - lr: 3.9811e-05\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.3115 - mean_absolute_error: 0.2884 - val_loss: 0.0835 - val_mean_absolute_error: 0.0777 - lr: 4.7863e-05\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.3102 - mean_absolute_error: 0.2886 - val_loss: 0.0832 - val_mean_absolute_error: 0.0814 - lr: 5.7544e-05\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.3065 - mean_absolute_error: 0.2887 - val_loss: 0.0829 - val_mean_absolute_error: 0.0880 - lr: 6.9183e-05\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.3056 - mean_absolute_error: 0.2923 - val_loss: 0.0828 - val_mean_absolute_error: 0.0980 - lr: 8.3176e-05\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.3002 - mean_absolute_error: 0.2950 - val_loss: 0.0831 - val_mean_absolute_error: 0.1117 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.2978 - mean_absolute_error: 0.3031 - val_loss: 0.0841 - val_mean_absolute_error: 0.1269 - lr: 1.2023e-04\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.2953 - mean_absolute_error: 0.3075 - val_loss: 0.0851 - val_mean_absolute_error: 0.1368 - lr: 1.4454e-04\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.2850 - mean_absolute_error: 0.3008 - val_loss: 0.0832 - val_mean_absolute_error: 0.1243 - lr: 1.7378e-04\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.2673 - mean_absolute_error: 0.2824 - val_loss: 0.0801 - val_mean_absolute_error: 0.0932 - lr: 2.0893e-04\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.2506 - mean_absolute_error: 0.2653 - val_loss: 0.0783 - val_mean_absolute_error: 0.0764 - lr: 2.5119e-04\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.2396 - mean_absolute_error: 0.2514 - val_loss: 0.0762 - val_mean_absolute_error: 0.0710 - lr: 3.0200e-04\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 0.2300 - mean_absolute_error: 0.2398 - val_loss: 0.0736 - val_mean_absolute_error: 0.0696 - lr: 3.6308e-04\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.2261 - mean_absolute_error: 0.2336 - val_loss: 0.0709 - val_mean_absolute_error: 0.0684 - lr: 4.3652e-04\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.2212 - mean_absolute_error: 0.2273 - val_loss: 0.0686 - val_mean_absolute_error: 0.0671 - lr: 5.2481e-04\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 0.2140 - mean_absolute_error: 0.2213 - val_loss: 0.0662 - val_mean_absolute_error: 0.0651 - lr: 6.3096e-04\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2091 - mean_absolute_error: 0.2168 - val_loss: 0.0636 - val_mean_absolute_error: 0.0627 - lr: 7.5858e-04\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 16s 50ms/step - loss: 0.2041 - mean_absolute_error: 0.2136 - val_loss: 0.0618 - val_mean_absolute_error: 0.0612 - lr: 9.1201e-04\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.2004 - mean_absolute_error: 0.2117 - val_loss: 0.0602 - val_mean_absolute_error: 0.0659 - lr: 0.0011\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.1971 - mean_absolute_error: 0.2115 - val_loss: 0.0585 - val_mean_absolute_error: 0.0652 - lr: 0.0013\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.1932 - mean_absolute_error: 0.2117 - val_loss: 0.0572 - val_mean_absolute_error: 0.0733 - lr: 0.0016\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.1858 - mean_absolute_error: 0.2105 - val_loss: 0.0545 - val_mean_absolute_error: 0.0660 - lr: 0.0019\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.1718 - mean_absolute_error: 0.1992 - val_loss: 0.0509 - val_mean_absolute_error: 0.0589 - lr: 0.0023\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.1610 - mean_absolute_error: 0.1881 - val_loss: 0.0466 - val_mean_absolute_error: 0.0539 - lr: 0.0028\n",
      "Epoch 95/100\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.1535 - mean_absolute_error: 0.1814 - val_loss: 0.0430 - val_mean_absolute_error: 0.0525 - lr: 0.0033\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.1463 - mean_absolute_error: 0.1761 - val_loss: 0.0414 - val_mean_absolute_error: 0.0516 - lr: 0.0040\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.1414 - mean_absolute_error: 0.1720 - val_loss: 0.0407 - val_mean_absolute_error: 0.0565 - lr: 0.0048\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.1388 - mean_absolute_error: 0.1706 - val_loss: 0.0414 - val_mean_absolute_error: 0.0513 - lr: 0.0058\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.1353 - mean_absolute_error: 0.1680 - val_loss: 0.0412 - val_mean_absolute_error: 0.0561 - lr: 0.0069\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.1326 - mean_absolute_error: 0.1674 - val_loss: 0.0406 - val_mean_absolute_error: 0.0558 - lr: 0.0083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00017378008"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_groups = test_data_indx.groupby(level=names)\n",
    "def test_data_gen(groups=test_groups):\n",
    "        for index, frame in iter(groups):\n",
    "            matrix = frame.to_numpy()\n",
    "            students = matrix[:,0]\n",
    "            grades = matrix[:,1].astype(np.float64)\n",
    "            index = np.array([str(i) for i in index])\n",
    "            yield (index, students), grades\n",
    "test_dataset = tf.data.Dataset.from_generator(test_data_gen,\n",
    "    output_types=((tf.string, tf.string), tf.float64),\n",
    "    output_shapes=((tf.TensorShape([len(multi_label)]),\n",
    "        tf.TensorShape([None])),\n",
    "        tf.TensorShape([None])),\n",
    "    )\n",
    "test_dataset = test_dataset.map(map_func=lambda x, y: transform_data(x, y),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    # deterministic=False\n",
    "    )\n",
    "test_dataset = batching(test_dataset)\n",
    "test_steps = int((numdata*0.2/0.8**2)/batch_size)\n",
    "loss_untrained, metrics_untrained = encoder.evaluate(test_dataset, steps=test_steps)\n",
    "\n",
    "val_groups = validation_data_indx.groupby(level=names)\n",
    "def val_data_gen(groups=val_groups):\n",
    "    while True:\n",
    "        for index, frame in iter(groups):\n",
    "            matrix = frame.to_numpy()\n",
    "            students = matrix[:,0]\n",
    "            grades = matrix[:,1].astype(np.float64)\n",
    "            index = np.array([str(i) for i in index])\n",
    "            yield (index, students), grades\n",
    "val_dataset = tf.data.Dataset.from_generator(val_data_gen,\n",
    "    output_types=((tf.string, tf.string), tf.float64),\n",
    "    output_shapes=((tf.TensorShape([len(multi_label)]),\n",
    "        tf.TensorShape([None])),\n",
    "        tf.TensorShape([None])),\n",
    "    )\n",
    "val_dataset = val_dataset.map(lambda x, y: transform_data(x, y),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    # deterministic=False\n",
    "    )\n",
    "val_dataset = batching(val_dataset)\n",
    "val_steps = int((numdata*0.2/0.8)/batch_size)\n",
    "\n",
    "history= encoder.fit(train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=total_epochs,\n",
    "    callbacks=[tensorboard_callback, early_cb, lr_schedule],\n",
    "    use_multiprocessing=True,\n",
    "    workers=tf.data.experimental.AUTOTUNE,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=val_steps\n",
    "    )\n",
    "\n",
    "best_lr(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 7s 72ms/step - loss: 0.0510 - mean_absolute_error: 0.0664\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(history.history[\"loss\"], history.history[\"lr\"])\n",
    "run_savedir = get_run_dir(\"records/clean_subjects/glorot/5bit-dim/noise_s08-p04\")\n",
    "encoder.save(run_savedir.as_posix()+'/subj_focus.h5')\n",
    "\n",
    "loss_trained, metrics_trained = encoder.evaluate(test_dataset, steps=test_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('Algos-y-Estructuras': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7eba32832bba5edd130fa314053240f1de890276c151ad5a56f1cb9163750ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
